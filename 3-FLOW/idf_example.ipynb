{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch_model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_model_summary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCLAIMER**\n",
    "\n",
    "The presented code is not optimized, it serves an educational purpose. It is written for CPU, it uses only fully-connected networks and an extremely simplistic dataset. However, it contains all components that can help to understand how IDF works, and it should be rather easy to extend it to more sophisticated models. This code could be run almost on any laptop/PC, and it takes a couple of minutes top to get the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we go wild and use a dataset that is simpler than MNIST! We use a scipy dataset called Digits. It consists of ~1500 images of size 8x8, and each pixel can take values in $\\{0, 1, \\ldots, 16\\}$.\n",
    "\n",
    "The goal of using this dataset is that everyone can run it on a laptop, without any gpu etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Digits(Dataset):\n",
    "    \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, mode='train', transforms=None):\n",
    "        digits = load_digits()\n",
    "        if mode == 'train':\n",
    "            self.data = digits.data[:1000].astype(np.float32)\n",
    "        elif mode == 'val':\n",
    "            self.data = digits.data[1000:1350].astype(np.float32)\n",
    "        else:\n",
    "            self.data = digits.data[1350:].astype(np.float32)\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chakraborty & Chakravarty, \"A new discrete probability distribution with integer support on (−∞, ∞)\",\n",
    "#  Communications in Statistics - Theory and Methods, 45:2, 492-505, DOI: 10.1080/03610926.2013.830743\n",
    "\n",
    "def log_min_exp(a, b, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Source: https://github.com/jornpeters/integer_discrete_flows\n",
    "    Computes the log of exp(a) - exp(b) in a (more) numerically stable fashion.\n",
    "    Using:\n",
    "     log(exp(a) - exp(b))\n",
    "     c + log(exp(a-c) - exp(b-c))\n",
    "     a + log(1 - exp(b-a))\n",
    "    And note that we assume b < a always.\n",
    "    \"\"\"\n",
    "    y = a + torch.log(1 - torch.exp(b - a) + epsilon)\n",
    "\n",
    "    return y\n",
    "\n",
    "def log_integer_probability(x, mean, logscale):\n",
    "    scale = torch.exp(logscale)\n",
    "\n",
    "    logp = log_min_exp(\n",
    "        F.logsigmoid((x + 0.5 - mean) / scale),\n",
    "        F.logsigmoid((x - 0.5 - mean) / scale))\n",
    "\n",
    "    return logp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDF code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see the blogpost for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/jornpeters/integer_discrete_flows\n",
    "class RoundStraightThrough(torch.autograd.Function):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        rounded = torch.round(input, out=None)\n",
    "        return rounded\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_input = grad_output.clone()\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDF(nn.Module):\n",
    "    def __init__(self, netts, num_flows, D=2):\n",
    "        super(IDF, self).__init__()\n",
    "\n",
    "        print('IDF by JT.')\n",
    "        \n",
    "        if len(netts) == 1:\n",
    "            self.t = torch.nn.ModuleList([netts[0]() for _ in range(num_flows)])\n",
    "            self.idf_git = 1\n",
    "        \n",
    "        elif len(netts) == 4:\n",
    "            self.t_a = torch.nn.ModuleList([netts[0]() for _ in range(num_flows)])\n",
    "            self.t_b = torch.nn.ModuleList([netts[1]() for _ in range(num_flows)])\n",
    "            self.t_c = torch.nn.ModuleList([netts[2]() for _ in range(num_flows)])\n",
    "            self.t_d = torch.nn.ModuleList([netts[3]() for _ in range(num_flows)])\n",
    "            self.idf_git = 4\n",
    "        \n",
    "        else:\n",
    "            raise ValueError('You can provide either 1 or 4 translation nets.')\n",
    "        \n",
    "        self.num_flows = num_flows\n",
    "\n",
    "        self.round = RoundStraightThrough.apply\n",
    "        \n",
    "        self.mean = nn.Parameter(torch.zeros(1, D))\n",
    "        self.logscale = nn.Parameter(torch.ones(1, D))\n",
    "\n",
    "        self.D = D\n",
    "\n",
    "    def coupling(self, x, index, forward=True):\n",
    "        \n",
    "        if self.idf_git == 1:\n",
    "            (xa, xb) = torch.chunk(x, 2, 1)\n",
    "            \n",
    "            if forward:\n",
    "                yb = xb + self.round(self.t[index](xa))\n",
    "            else:\n",
    "                yb = xb - self.round(self.t[index](xa))\n",
    "            \n",
    "            return torch.cat((xa, yb), 1)\n",
    "        \n",
    "        elif self.idf_git == 4:\n",
    "            (xa, xb, xc, xd) = torch.chunk(x, 4, 1)\n",
    "            \n",
    "            if forward:\n",
    "                ya = xa + self.round(self.t_a[index](torch.cat((xb, xc, xd), 1)))\n",
    "                yb = xb + self.round(self.t_b[index](torch.cat((ya, xc, xd), 1)))\n",
    "                yc = xc + self.round(self.t_c[index](torch.cat((ya, yb, xd), 1)))\n",
    "                yd = xd + self.round(self.t_d[index](torch.cat((ya, yb, yc), 1)))\n",
    "            else:\n",
    "                yd = xd - self.round(self.t_d[index](torch.cat((xa, xb, xc), 1)))\n",
    "                yc = xc - self.round(self.t_c[index](torch.cat((xa, xb, yd), 1)))\n",
    "                yb = xb - self.round(self.t_b[index](torch.cat((xa, yc, yd), 1)))\n",
    "                ya = xa - self.round(self.t_a[index](torch.cat((yb, yc, yd), 1)))\n",
    "            \n",
    "            return torch.cat((ya, yb, yc, yd), 1)\n",
    "\n",
    "    def permute(self, x):\n",
    "        return x.flip(1)\n",
    "\n",
    "    def f(self, x):\n",
    "        z = x\n",
    "        for i in range(self.num_flows):\n",
    "            z = self.coupling(z, i, forward=True)\n",
    "            z = self.permute(z)\n",
    "\n",
    "        return z\n",
    "\n",
    "    def f_inv(self, z):\n",
    "        x = z\n",
    "        for i in reversed(range(self.num_flows)):\n",
    "            x = self.permute(x)\n",
    "            x = self.coupling(x, i, forward=False)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, reduction='avg'):\n",
    "        z = self.f(x)\n",
    "        if reduction == 'sum':\n",
    "            return -self.log_prior(z).sum()\n",
    "        else:\n",
    "            return -self.log_prior(z).mean()\n",
    "\n",
    "    def sample(self, batchSize):\n",
    "        # sample z:\n",
    "        z = self.prior_sample(batchSize=batchSize, D=self.D)\n",
    "        # x = f^-1(z)\n",
    "        x = self.f_inv(z)\n",
    "        return x.view(batchSize, 1, self.D)\n",
    "\n",
    "    def log_prior(self, x):\n",
    "        log_p = log_integer_probability(x, self.mean, self.logscale)\n",
    "        return log_p.sum(1)\n",
    "\n",
    "    def prior_sample(self, batchSize, D=2):\n",
    "        # Sample from logistic\n",
    "        y = torch.rand(batchSize, self.D)\n",
    "        x = torch.exp(self.logscale) * torch.log(y / (1. - y)) + self.mean\n",
    "        # And then round it to an integer.\n",
    "        return torch.round(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions: training, evaluation, plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's rather self-explanatory, isn't it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
    "    # EVALUATION\n",
    "    if model_best is None:\n",
    "        # load best performing model\n",
    "        model_best = torch.load(name + '.model', weights_only=False)\n",
    "\n",
    "    model_best.eval()\n",
    "    loss = 0.\n",
    "    N = 0.\n",
    "    for indx_batch, test_batch in enumerate(test_loader):\n",
    "        loss_t = model_best.forward(test_batch, reduction='sum')\n",
    "        loss = loss + loss_t.item()\n",
    "        N = N + test_batch.shape[0]\n",
    "    loss = loss / N\n",
    "\n",
    "    if epoch is None:\n",
    "        print(f'FINAL LOSS: nll={loss}')\n",
    "    else:\n",
    "        print(f'Epoch: {epoch}, val nll={loss}')\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def samples_real(name, test_loader):\n",
    "    # REAL-------\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = next(iter(test_loader)).detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name+'_real_images.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def samples_generated(name, data_loader, extra_name=''):\n",
    "    x = next(iter(data_loader)).detach().numpy()\n",
    "\n",
    "    # GENERATIONS-------\n",
    "    model_best = torch.load(name + '.model', weights_only=False)\n",
    "    model_best.eval()\n",
    "\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = model_best.sample(num_x * num_y)\n",
    "    x = x.detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name + '_generated_images' + extra_name + '.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_curve(name, nll_val):\n",
    "    plt.plot(np.arange(len(nll_val)), nll_val, linewidth='3')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('nll')\n",
    "    plt.savefig(name + '_nll_val_curve.pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader):\n",
    "    nll_val = []\n",
    "    best_nll = 1000.\n",
    "    patience = 0\n",
    "\n",
    "    # Main loop\n",
    "    for e in range(num_epochs):\n",
    "        # TRAINING\n",
    "        model.train()\n",
    "        for indx_batch, batch in enumerate(training_loader):\n",
    "            \n",
    "            loss = model.forward(batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        loss_val = evaluation(val_loader, model_best=model, epoch=e)\n",
    "        nll_val.append(loss_val)  # save for plotting\n",
    "\n",
    "        if e == 0:\n",
    "            print('saved!')\n",
    "            torch.save(model, name + '.model')\n",
    "            best_nll = loss_val\n",
    "        else:\n",
    "            if loss_val < best_nll:\n",
    "                print('saved!')\n",
    "                torch.save(model, name + '.model')\n",
    "                best_nll = loss_val\n",
    "                patience = 0\n",
    "\n",
    "                samples_generated(name, val_loader, extra_name=\"_epoch_\" + str(e))\n",
    "            else:\n",
    "                patience = patience + 1\n",
    "\n",
    "        if patience > max_patience:\n",
    "            break\n",
    "\n",
    "    nll_val = np.asarray(nll_val)\n",
    "\n",
    "    return nll_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Digits(mode='train')\n",
    "val_data = Digits(mode='val')\n",
    "test_data = Digits(mode='test')\n",
    "\n",
    "training_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "result_dir = 'results/'\n",
    "if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "name = 'idf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 64   # input dimension\n",
    "M = 256  # the number of neurons in scale (s) and translation (t) nets\n",
    "\n",
    "lr = 1e-3 # learning rate\n",
    "num_epochs = 1000 # max. number of epochs\n",
    "max_patience = 20 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF by JT.\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Linear-1            [1, 256]          12,544          12,544\n",
      "       LeakyReLU-2            [1, 256]               0               0\n",
      "          Linear-3            [1, 256]          65,792          65,792\n",
      "       LeakyReLU-4            [1, 256]               0               0\n",
      "          Linear-5             [1, 16]           4,112           4,112\n",
      "          Linear-6            [1, 256]          12,544          12,544\n",
      "       LeakyReLU-7            [1, 256]               0               0\n",
      "          Linear-8            [1, 256]          65,792          65,792\n",
      "       LeakyReLU-9            [1, 256]               0               0\n",
      "         Linear-10             [1, 16]           4,112           4,112\n",
      "         Linear-11            [1, 256]          12,544          12,544\n",
      "      LeakyReLU-12            [1, 256]               0               0\n",
      "         Linear-13            [1, 256]          65,792          65,792\n",
      "      LeakyReLU-14            [1, 256]               0               0\n",
      "         Linear-15             [1, 16]           4,112           4,112\n",
      "         Linear-16            [1, 256]          12,544          12,544\n",
      "      LeakyReLU-17            [1, 256]               0               0\n",
      "         Linear-18            [1, 256]          65,792          65,792\n",
      "      LeakyReLU-19            [1, 256]               0               0\n",
      "         Linear-20             [1, 16]           4,112           4,112\n",
      "         Linear-21            [1, 256]          12,544          12,544\n",
      "      LeakyReLU-22            [1, 256]               0               0\n",
      "         Linear-23            [1, 256]          65,792          65,792\n",
      "      LeakyReLU-24            [1, 256]               0               0\n",
      "         Linear-25             [1, 16]           4,112           4,112\n",
      "         Linear-26            [1, 256]          12,544          12,544\n",
      "      LeakyReLU-27            [1, 256]               0               0\n",
      "         Linear-28            [1, 256]          65,792          65,792\n",
      "      LeakyReLU-29            [1, 256]               0               0\n",
      "         Linear-30             [1, 16]           4,112           4,112\n",
      "         Linear-31            [1, 256]          12,544          12,544\n",
      "      LeakyReLU-32            [1, 256]               0               0\n",
      "         Linear-33            [1, 256]          65,792          65,792\n",
      "      LeakyReLU-34            [1, 256]               0               0\n",
      "         Linear-35             [1, 16]           4,112           4,112\n",
      "         Linear-36            [1, 256]          12,544          12,544\n",
      "      LeakyReLU-37            [1, 256]               0               0\n",
      "         Linear-38            [1, 256]          65,792          65,792\n",
      "      LeakyReLU-39            [1, 256]               0               0\n",
      "         Linear-40             [1, 16]           4,112           4,112\n",
      "         Linear-41            [1, 256]          12,544          12,544\n",
      "      LeakyReLU-42            [1, 256]               0               0\n",
      "         Linear-43            [1, 256]          65,792          65,792\n",
      "      LeakyReLU-44            [1, 256]               0               0\n",
      "         Linear-45             [1, 16]           4,112           4,112\n",
      "         Linear-46            [1, 256]          12,544          12,544\n",
      "      LeakyReLU-47            [1, 256]               0               0\n",
      "         Linear-48            [1, 256]          65,792          65,792\n",
      "      LeakyReLU-49            [1, 256]               0               0\n",
      "         Linear-50             [1, 16]           4,112           4,112\n",
      "         Linear-51            [1, 256]          12,544          12,544\n",
      "      LeakyReLU-52            [1, 256]               0               0\n",
      "         Linear-53            [1, 256]          65,792          65,792\n",
      "      LeakyReLU-54            [1, 256]               0               0\n",
      "         Linear-55             [1, 16]           4,112           4,112\n",
      "         Linear-56            [1, 256]          12,544          12,544\n",
      "      LeakyReLU-57            [1, 256]               0               0\n",
      "         Linear-58            [1, 256]          65,792          65,792\n",
      "      LeakyReLU-59            [1, 256]               0               0\n",
      "         Linear-60             [1, 16]           4,112           4,112\n",
      "         Linear-61            [1, 256]          12,544          12,544\n",
      "      LeakyReLU-62            [1, 256]               0               0\n",
      "         Linear-63            [1, 256]          65,792          65,792\n",
      "      LeakyReLU-64            [1, 256]               0               0\n",
      "         Linear-65             [1, 16]           4,112           4,112\n",
      "         Linear-66            [1, 256]          12,544          12,544\n",
      "      LeakyReLU-67            [1, 256]               0               0\n",
      "         Linear-68            [1, 256]          65,792          65,792\n",
      "      LeakyReLU-69            [1, 256]               0               0\n",
      "         Linear-70             [1, 16]           4,112           4,112\n",
      "         Linear-71            [1, 256]          12,544          12,544\n",
      "      LeakyReLU-72            [1, 256]               0               0\n",
      "         Linear-73            [1, 256]          65,792          65,792\n",
      "      LeakyReLU-74            [1, 256]               0               0\n",
      "         Linear-75             [1, 16]           4,112           4,112\n",
      "         Linear-76            [1, 256]          12,544          12,544\n",
      "      LeakyReLU-77            [1, 256]               0               0\n",
      "         Linear-78            [1, 256]          65,792          65,792\n",
      "      LeakyReLU-79            [1, 256]               0               0\n",
      "         Linear-80             [1, 16]           4,112           4,112\n",
      "         Linear-81            [1, 256]          12,544          12,544\n",
      "      LeakyReLU-82            [1, 256]               0               0\n",
      "         Linear-83            [1, 256]          65,792          65,792\n",
      "      LeakyReLU-84            [1, 256]               0               0\n",
      "         Linear-85             [1, 16]           4,112           4,112\n",
      "         Linear-86            [1, 256]          12,544          12,544\n",
      "      LeakyReLU-87            [1, 256]               0               0\n",
      "         Linear-88            [1, 256]          65,792          65,792\n",
      "      LeakyReLU-89            [1, 256]               0               0\n",
      "         Linear-90             [1, 16]           4,112           4,112\n",
      "         Linear-91            [1, 256]          12,544          12,544\n",
      "      LeakyReLU-92            [1, 256]               0               0\n",
      "         Linear-93            [1, 256]          65,792          65,792\n",
      "      LeakyReLU-94            [1, 256]               0               0\n",
      "         Linear-95             [1, 16]           4,112           4,112\n",
      "         Linear-96            [1, 256]          12,544          12,544\n",
      "      LeakyReLU-97            [1, 256]               0               0\n",
      "         Linear-98            [1, 256]          65,792          65,792\n",
      "      LeakyReLU-99            [1, 256]               0               0\n",
      "        Linear-100             [1, 16]           4,112           4,112\n",
      "        Linear-101            [1, 256]          12,544          12,544\n",
      "     LeakyReLU-102            [1, 256]               0               0\n",
      "        Linear-103            [1, 256]          65,792          65,792\n",
      "     LeakyReLU-104            [1, 256]               0               0\n",
      "        Linear-105             [1, 16]           4,112           4,112\n",
      "        Linear-106            [1, 256]          12,544          12,544\n",
      "     LeakyReLU-107            [1, 256]               0               0\n",
      "        Linear-108            [1, 256]          65,792          65,792\n",
      "     LeakyReLU-109            [1, 256]               0               0\n",
      "        Linear-110             [1, 16]           4,112           4,112\n",
      "        Linear-111            [1, 256]          12,544          12,544\n",
      "     LeakyReLU-112            [1, 256]               0               0\n",
      "        Linear-113            [1, 256]          65,792          65,792\n",
      "     LeakyReLU-114            [1, 256]               0               0\n",
      "        Linear-115             [1, 16]           4,112           4,112\n",
      "        Linear-116            [1, 256]          12,544          12,544\n",
      "     LeakyReLU-117            [1, 256]               0               0\n",
      "        Linear-118            [1, 256]          65,792          65,792\n",
      "     LeakyReLU-119            [1, 256]               0               0\n",
      "        Linear-120             [1, 16]           4,112           4,112\n",
      "        Linear-121            [1, 256]          12,544          12,544\n",
      "     LeakyReLU-122            [1, 256]               0               0\n",
      "        Linear-123            [1, 256]          65,792          65,792\n",
      "     LeakyReLU-124            [1, 256]               0               0\n",
      "        Linear-125             [1, 16]           4,112           4,112\n",
      "        Linear-126            [1, 256]          12,544          12,544\n",
      "     LeakyReLU-127            [1, 256]               0               0\n",
      "        Linear-128            [1, 256]          65,792          65,792\n",
      "     LeakyReLU-129            [1, 256]               0               0\n",
      "        Linear-130             [1, 16]           4,112           4,112\n",
      "        Linear-131            [1, 256]          12,544          12,544\n",
      "     LeakyReLU-132            [1, 256]               0               0\n",
      "        Linear-133            [1, 256]          65,792          65,792\n",
      "     LeakyReLU-134            [1, 256]               0               0\n",
      "        Linear-135             [1, 16]           4,112           4,112\n",
      "        Linear-136            [1, 256]          12,544          12,544\n",
      "     LeakyReLU-137            [1, 256]               0               0\n",
      "        Linear-138            [1, 256]          65,792          65,792\n",
      "     LeakyReLU-139            [1, 256]               0               0\n",
      "        Linear-140             [1, 16]           4,112           4,112\n",
      "        Linear-141            [1, 256]          12,544          12,544\n",
      "     LeakyReLU-142            [1, 256]               0               0\n",
      "        Linear-143            [1, 256]          65,792          65,792\n",
      "     LeakyReLU-144            [1, 256]               0               0\n",
      "        Linear-145             [1, 16]           4,112           4,112\n",
      "        Linear-146            [1, 256]          12,544          12,544\n",
      "     LeakyReLU-147            [1, 256]               0               0\n",
      "        Linear-148            [1, 256]          65,792          65,792\n",
      "     LeakyReLU-149            [1, 256]               0               0\n",
      "        Linear-150             [1, 16]           4,112           4,112\n",
      "        Linear-151            [1, 256]          12,544          12,544\n",
      "     LeakyReLU-152            [1, 256]               0               0\n",
      "        Linear-153            [1, 256]          65,792          65,792\n",
      "     LeakyReLU-154            [1, 256]               0               0\n",
      "        Linear-155             [1, 16]           4,112           4,112\n",
      "        Linear-156            [1, 256]          12,544          12,544\n",
      "     LeakyReLU-157            [1, 256]               0               0\n",
      "        Linear-158            [1, 256]          65,792          65,792\n",
      "     LeakyReLU-159            [1, 256]               0               0\n",
      "        Linear-160             [1, 16]           4,112           4,112\n",
      "=======================================================================\n",
      "Total params: 2,638,336\n",
      "Trainable params: 2,638,336\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# The number of invertible transformations\n",
    "num_flows = 8\n",
    "\n",
    "# This variable defines whether we use: \n",
    "#   1 - the classic coupling layer proposed in (Hogeboom et al., 2019)\n",
    "#   4 - the general invertible transformation in (Tomczak, 2020) with 4 partitions\n",
    "idf_git = 4\n",
    "\n",
    "if idf_git == 1:\n",
    "    nett = lambda: nn.Sequential(nn.Linear(D // 2, M), nn.LeakyReLU(),\n",
    "                                     nn.Linear(M, M), nn.LeakyReLU(),\n",
    "                                     nn.Linear(M, D // 2))\n",
    "    netts = [nett]\n",
    "\n",
    "elif idf_git == 4:\n",
    "    nett_a = lambda: nn.Sequential(nn.Linear(3 * (D // 4), M), nn.LeakyReLU(),\n",
    "                                       nn.Linear(M, M), nn.LeakyReLU(),\n",
    "                                       nn.Linear(M, D // 4))\n",
    "\n",
    "    nett_b = lambda: nn.Sequential(nn.Linear(3 * (D // 4), M), nn.LeakyReLU(),\n",
    "                                       nn.Linear(M, M), nn.LeakyReLU(),\n",
    "                                       nn.Linear(M, D // 4))\n",
    "\n",
    "    nett_c = lambda: nn.Sequential(nn.Linear(3 * (D // 4), M), nn.LeakyReLU(),\n",
    "                                       nn.Linear(M, M), nn.LeakyReLU(),\n",
    "                                       nn.Linear(M, D // 4))\n",
    "\n",
    "    nett_d = lambda: nn.Sequential(nn.Linear(3 * (D // 4), M), nn.LeakyReLU(),\n",
    "                                       nn.Linear(M, M), nn.LeakyReLU(),\n",
    "                                       nn.Linear(M, D // 4))\n",
    "    \n",
    "    netts = [nett_a, nett_b, nett_c, nett_d]\n",
    "\n",
    "# Init IDF\n",
    "model = IDF(netts, num_flows, D=D)\n",
    "# Print the summary (like in Keras)\n",
    "print(summary(model, torch.zeros(1, 64), show_input=False, show_hierarchical=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's play! Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZER\n",
    "optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, val nll=179.05726143973214\n",
      "saved!\n",
      "Epoch: 1, val nll=175.12359235491073\n",
      "saved!\n",
      "Epoch: 2, val nll=172.8280454799107\n",
      "saved!\n",
      "Epoch: 3, val nll=170.999892578125\n",
      "saved!\n",
      "Epoch: 4, val nll=169.18381277901787\n",
      "saved!\n",
      "Epoch: 5, val nll=168.07904017857143\n",
      "saved!\n",
      "Epoch: 6, val nll=166.74080915178573\n",
      "saved!\n",
      "Epoch: 7, val nll=165.52686941964285\n",
      "saved!\n",
      "Epoch: 8, val nll=164.67981863839285\n",
      "saved!\n",
      "Epoch: 9, val nll=163.95080357142857\n",
      "saved!\n",
      "Epoch: 10, val nll=162.78873744419644\n",
      "saved!\n",
      "Epoch: 11, val nll=162.29602678571428\n",
      "saved!\n",
      "Epoch: 12, val nll=161.27506277901784\n",
      "saved!\n",
      "Epoch: 13, val nll=160.60529436383928\n",
      "saved!\n",
      "Epoch: 14, val nll=160.04686941964286\n",
      "saved!\n",
      "Epoch: 15, val nll=159.23106305803572\n",
      "saved!\n",
      "Epoch: 16, val nll=158.71605747767856\n",
      "saved!\n",
      "Epoch: 17, val nll=158.11680943080358\n",
      "saved!\n",
      "Epoch: 18, val nll=157.38629464285714\n",
      "saved!\n",
      "Epoch: 19, val nll=157.03651227678571\n",
      "saved!\n",
      "Epoch: 20, val nll=156.23029436383928\n",
      "saved!\n",
      "Epoch: 21, val nll=156.09865792410713\n",
      "saved!\n",
      "Epoch: 22, val nll=155.53878348214286\n",
      "saved!\n",
      "Epoch: 23, val nll=154.89308035714285\n",
      "saved!\n",
      "Epoch: 24, val nll=154.60044642857142\n",
      "saved!\n",
      "Epoch: 25, val nll=153.85151088169644\n",
      "saved!\n",
      "Epoch: 26, val nll=153.64020089285714\n",
      "saved!\n",
      "Epoch: 27, val nll=153.115859375\n",
      "saved!\n",
      "Epoch: 28, val nll=152.8772767857143\n",
      "saved!\n",
      "Epoch: 29, val nll=152.6024888392857\n",
      "saved!\n",
      "Epoch: 30, val nll=151.70568777901786\n",
      "saved!\n",
      "Epoch: 31, val nll=151.64980747767856\n",
      "saved!\n",
      "Epoch: 32, val nll=151.1371693638393\n",
      "saved!\n",
      "Epoch: 33, val nll=150.97789341517858\n",
      "saved!\n",
      "Epoch: 34, val nll=150.43403878348215\n",
      "saved!\n",
      "Epoch: 35, val nll=150.15257254464285\n",
      "saved!\n",
      "Epoch: 36, val nll=149.96670340401786\n",
      "saved!\n",
      "Epoch: 37, val nll=149.82337053571428\n",
      "saved!\n",
      "Epoch: 38, val nll=149.14704938616072\n",
      "saved!\n",
      "Epoch: 39, val nll=149.1813462611607\n",
      "Epoch: 40, val nll=148.73761021205357\n",
      "saved!\n",
      "Epoch: 41, val nll=148.21619698660714\n",
      "saved!\n",
      "Epoch: 42, val nll=147.9117006138393\n",
      "saved!\n",
      "Epoch: 43, val nll=147.94694475446428\n",
      "Epoch: 44, val nll=147.77408761160714\n",
      "saved!\n",
      "Epoch: 45, val nll=147.23013671875\n",
      "saved!\n",
      "Epoch: 46, val nll=146.87397879464285\n",
      "saved!\n",
      "Epoch: 47, val nll=147.14594029017857\n",
      "Epoch: 48, val nll=146.393017578125\n",
      "saved!\n",
      "Epoch: 49, val nll=146.5038267299107\n",
      "Epoch: 50, val nll=146.20732700892856\n",
      "saved!\n",
      "Epoch: 51, val nll=145.83540736607142\n",
      "saved!\n",
      "Epoch: 52, val nll=146.03662667410714\n",
      "Epoch: 53, val nll=146.18987583705356\n",
      "Epoch: 54, val nll=145.64575892857144\n",
      "saved!\n",
      "Epoch: 55, val nll=145.7012681361607\n",
      "Epoch: 56, val nll=145.3045228794643\n",
      "saved!\n",
      "Epoch: 57, val nll=145.462880859375\n",
      "Epoch: 58, val nll=144.942734375\n",
      "saved!\n",
      "Epoch: 59, val nll=144.83392996651784\n",
      "saved!\n",
      "Epoch: 60, val nll=144.9775474330357\n",
      "Epoch: 61, val nll=144.71985909598214\n",
      "saved!\n",
      "Epoch: 62, val nll=145.19625279017856\n",
      "Epoch: 63, val nll=144.49055943080356\n",
      "saved!\n",
      "Epoch: 64, val nll=144.63262137276786\n",
      "Epoch: 65, val nll=144.8325795200893\n",
      "Epoch: 66, val nll=144.81302315848214\n",
      "Epoch: 67, val nll=145.0153138950893\n",
      "Epoch: 68, val nll=144.4850279017857\n",
      "saved!\n",
      "Epoch: 69, val nll=144.5843763950893\n",
      "Epoch: 70, val nll=144.72767996651785\n",
      "Epoch: 71, val nll=144.64544921875\n",
      "Epoch: 72, val nll=145.43837332589285\n",
      "Epoch: 73, val nll=144.75428431919642\n",
      "Epoch: 74, val nll=144.91786830357142\n",
      "Epoch: 75, val nll=145.18366350446428\n",
      "Epoch: 76, val nll=144.99236328125\n",
      "Epoch: 77, val nll=144.63015066964286\n",
      "Epoch: 78, val nll=145.56506417410714\n",
      "Epoch: 79, val nll=145.26164899553572\n",
      "Epoch: 80, val nll=145.2574888392857\n",
      "Epoch: 81, val nll=146.30626116071429\n",
      "Epoch: 82, val nll=145.93392996651787\n",
      "Epoch: 83, val nll=145.56557896205356\n",
      "Epoch: 84, val nll=145.52623325892858\n",
      "Epoch: 85, val nll=145.87510602678572\n",
      "Epoch: 86, val nll=146.75353934151786\n",
      "Epoch: 87, val nll=147.17861188616072\n",
      "Epoch: 88, val nll=146.30230329241073\n",
      "Epoch: 89, val nll=146.36187220982143\n"
     ]
    }
   ],
   "source": [
    "# Training procedure\n",
    "nll_val = training(name=result_dir + name, max_patience=max_patience, num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                       training_loader=training_loader, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL __main__.IDF was not an allowed global by default. Please use `torch.serialization.add_safe_globals([__main__.IDF])` or the `torch.serialization.safe_globals([__main__.IDF])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test_loss = \u001b[43mevaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresult_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m f = \u001b[38;5;28mopen\u001b[39m(result_dir + name + \u001b[33m'\u001b[39m\u001b[33m_test_loss.txt\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m f.write(\u001b[38;5;28mstr\u001b[39m(test_loss))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mevaluation\u001b[39m\u001b[34m(test_loader, name, model_best, epoch)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluation\u001b[39m(test_loader, name=\u001b[38;5;28;01mNone\u001b[39;00m, model_best=\u001b[38;5;28;01mNone\u001b[39;00m, epoch=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# EVALUATION\u001b[39;00m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_best \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      4\u001b[39m         \u001b[38;5;66;03m# load best performing model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m         model_best = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m.model\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     model_best.eval()\n\u001b[32m      8\u001b[39m     loss = \u001b[32m0.\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/gnn/lib/python3.12/site-packages/torch/serialization.py:1524\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1516\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1517\u001b[39m                     opened_zipfile,\n\u001b[32m   1518\u001b[39m                     map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1521\u001b[39m                     **pickle_load_args,\n\u001b[32m   1522\u001b[39m                 )\n\u001b[32m   1523\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1524\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1525\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1526\u001b[39m             opened_zipfile,\n\u001b[32m   1527\u001b[39m             map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1530\u001b[39m             **pickle_load_args,\n\u001b[32m   1531\u001b[39m         )\n\u001b[32m   1532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[31mUnpicklingError\u001b[39m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL __main__.IDF was not an allowed global by default. Please use `torch.serialization.add_safe_globals([__main__.IDF])` or the `torch.serialization.safe_globals([__main__.IDF])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "test_loss = evaluation(name=result_dir + name, test_loader=test_loader)\n",
    "f = open(result_dir + name + '_test_loss.txt', \"w\")\n",
    "f.write(str(test_loss))\n",
    "f.close()\n",
    "\n",
    "samples_real(result_dir + name, test_loader)\n",
    "\n",
    "plot_curve(result_dir + name, nll_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
