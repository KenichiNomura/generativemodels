{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MF7BncmmLBeO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCLAIMER**\n",
    "\n",
    "The presented code is not optimized, it serves an educational purpose. It is written for CPU, it uses only fully-connected networks and an extremely simplistic dataset. However, it contains all components that can help to understand how a diffusion-based deep generative model (DDGM, a.k.a. a deep diffusion probabilistic model) works, and it should be rather easy to extend it to more sophisticated models. This code could be run almost on any laptop/PC, and it takes a couple of minutes top to get the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKsmjLumL5A2",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Dataset: Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we go wild and use a dataset that is simpler than MNIST! We use a scipy dataset called Digits. It consists of ~1500 images of size 8x8, and each pixel can take values in $\\{0, 1, \\ldots, 16\\}$.\n",
    "\n",
    "The goal of using this dataset is that everyone can run it on a laptop, without any gpu etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hSWUnXAYLLif"
   },
   "outputs": [],
   "source": [
    "class Digits(Dataset):\n",
    "    \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, mode='train', transforms=None):\n",
    "        digits = load_digits()\n",
    "        if mode == 'train':\n",
    "            self.data = digits.data[:1000].astype(np.float32)\n",
    "        elif mode == 'val':\n",
    "            self.data = digits.data[1000:1350].astype(np.float32)\n",
    "        else:\n",
    "            self.data = digits.data[1350:].astype(np.float32)\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQyrkrqAL7p8"
   },
   "source": [
    "## Auxiliary functions and classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tw00sH-6L9yg"
   },
   "source": [
    "### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AJh8NiXxLNf9"
   },
   "outputs": [],
   "source": [
    "PI = torch.from_numpy(np.asarray(np.pi))\n",
    "EPS = 1.e-7\n",
    "\n",
    "def log_categorical(x, p, num_classes=256, reduction=None, dim=None):\n",
    "    x_one_hot = F.one_hot(x.long(), num_classes=num_classes)\n",
    "    log_p = x_one_hot * torch.log(torch.clamp(p, EPS, 1. - EPS))\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "def log_bernoulli(x, p, reduction=None, dim=None):\n",
    "    pp = torch.clamp(p, EPS, 1. - EPS)\n",
    "    log_p = x * torch.log(pp) + (1. - x) * torch.log(1. - pp)\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "def log_normal_diag(x, mu, log_var, reduction=None, dim=None):\n",
    "    log_p = -0.5 * torch.log(2. * PI) - 0.5 * log_var - 0.5 * torch.exp(-log_var) * (x - mu)**2.\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "def log_standard_normal(x, reduction=None, dim=None):\n",
    "    log_p = -0.5 * torch.log(2. * PI) - 0.5 * x**2.\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "# Chakraborty & Chakravarty, \"A new discrete probability distribution with integer support on (−∞, ∞)\",\n",
    "#  Communications in Statistics - Theory and Methods, 45:2, 492-505, DOI: 10.1080/03610926.2013.830743\n",
    "\n",
    "def log_min_exp(a, b, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Source: https://github.com/jornpeters/integer_discrete_flows\n",
    "    Computes the log of exp(a) - exp(b) in a (more) numerically stable fashion.\n",
    "    Using:\n",
    "    log(exp(a) - exp(b))\n",
    "    c + log(exp(a-c) - exp(b-c))\n",
    "    a + log(1 - exp(b-a))\n",
    "    And note that we assume b < a always.\n",
    "    \"\"\"\n",
    "    y = a + torch.log(1 - torch.exp(b - a) + epsilon)\n",
    "\n",
    "    return y\n",
    "\n",
    "def log_integer_probability(x, mean, logscale):\n",
    "    scale = torch.exp(logscale)\n",
    "\n",
    "    logp = log_min_exp(\n",
    "      F.logsigmoid((x + 0.5 - mean) / scale),\n",
    "      F.logsigmoid((x - 0.5 - mean) / scale))\n",
    "\n",
    "    return logp\n",
    "\n",
    "def log_integer_probability_standard(x):\n",
    "    logp = log_min_exp(\n",
    "      F.logsigmoid(x + 0.5),\n",
    "      F.logsigmoid(x - 0.5))\n",
    "\n",
    "    return logp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSP2qiMqMICK"
   },
   "source": [
    "## Diffusion-based Deep Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** Please note that we use a single class unlike in previous implementations of VAEs. We do it for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GRYA6JA4LWEC"
   },
   "outputs": [],
   "source": [
    "class DDGM(nn.Module):\n",
    "    def __init__(self, p_dnns, decoder_net, beta, T, D):\n",
    "        super(DDGM, self).__init__()\n",
    "\n",
    "        print('DDGM by JT.')\n",
    "\n",
    "        self.p_dnns = p_dnns  # a list of sequentials\n",
    "\n",
    "        self.decoder_net = decoder_net\n",
    "\n",
    "        # other params\n",
    "        self.D = D\n",
    "\n",
    "        self.T = T\n",
    "\n",
    "        self.beta = torch.FloatTensor([beta])\n",
    "\n",
    "    @staticmethod\n",
    "    def reparameterization(mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std * eps\n",
    "\n",
    "    def reparameterization_gaussian_diffusion(self, x, i):\n",
    "        return torch.sqrt(1. - self.beta) * x + torch.sqrt(self.beta) * torch.randn_like(x)\n",
    "\n",
    "    def forward(self, x, reduction='avg'):\n",
    "        # =====\n",
    "        # forward difussion\n",
    "        zs = [self.reparameterization_gaussian_diffusion(x, 0)]\n",
    "\n",
    "        for i in range(1, self.T):\n",
    "            zs.append(self.reparameterization_gaussian_diffusion(zs[-1], i))\n",
    "\n",
    "        # =====\n",
    "        # backward diffusion\n",
    "        mus = []\n",
    "        log_vars = []\n",
    "\n",
    "        for i in range(len(self.p_dnns) - 1, -1, -1):\n",
    "            h = self.p_dnns[i](zs[i+1])\n",
    "            mu_i, log_var_i = torch.chunk(h, 2, dim=1)\n",
    "            mus.append(mu_i)\n",
    "            log_vars.append(log_var_i)\n",
    "\n",
    "        mu_x = self.decoder_net(zs[0])\n",
    "\n",
    "        # =====ELBO\n",
    "        # RE\n",
    "        RE = log_standard_normal(x - mu_x).sum(-1)\n",
    "\n",
    "        # KL\n",
    "        KL = (log_normal_diag(zs[-1], torch.sqrt(1. - self.beta) * zs[-1], torch.log(self.beta)) - log_standard_normal(zs[-1])).sum(-1)\n",
    "\n",
    "        for i in range(len(mus)):\n",
    "            KL_i = (log_normal_diag(zs[i], torch.sqrt(1. - self.beta) * zs[i], torch.log(self.beta)) - log_normal_diag(zs[i], mus[i], log_vars[i])).sum(-1)\n",
    "\n",
    "            KL = KL + KL_i\n",
    "\n",
    "        # Final ELBO\n",
    "        if reduction == 'sum':\n",
    "            loss = -(RE - KL).sum()\n",
    "        else:\n",
    "            loss = -(RE - KL).mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def sample(self, batch_size=64):\n",
    "        z = torch.randn([batch_size, self.D])\n",
    "        for i in range(len(self.p_dnns) - 1, -1, -1):\n",
    "            h = self.p_dnns[i](z)\n",
    "            mu_i, log_var_i = torch.chunk(h, 2, dim=1)\n",
    "            z = self.reparameterization(torch.tanh(mu_i), log_var_i)\n",
    "\n",
    "        mu_x = self.decoder_net(z)\n",
    "\n",
    "        return mu_x\n",
    "\n",
    "    def sample_diffusion(self, x):\n",
    "        zs = [self.reparameterization_gaussian_diffusion(x, 0)]\n",
    "\n",
    "        for i in range(1, self.T):\n",
    "            zs.append(self.reparameterization_gaussian_diffusion(zs[-1], i))\n",
    "\n",
    "        return zs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUoPkTmrMVnx"
   },
   "source": [
    "## Evaluation and Training functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvwmRoi7MVto"
   },
   "source": [
    "**Evaluation step, sampling and curve plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JHx4RIqDLZe9"
   },
   "outputs": [],
   "source": [
    "def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
    "    # EVALUATION\n",
    "    if model_best is None:\n",
    "        # load best performing model\n",
    "        model_best = torch.load(name + '.model', weights_only=False)\n",
    "\n",
    "    model_best.eval()\n",
    "    loss = 0.\n",
    "    N = 0.\n",
    "    for indx_batch, test_batch in enumerate(test_loader):\n",
    "        loss_t = model_best.forward(test_batch, reduction='sum')\n",
    "        loss = loss + loss_t.item()\n",
    "        N = N + test_batch.shape[0]\n",
    "    loss = loss / N\n",
    "\n",
    "    if epoch is None:\n",
    "        print(f'FINAL LOSS: nll={loss}')\n",
    "    else:\n",
    "        print(f'Epoch: {epoch}, val nll={loss}')\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def samples_real(name, test_loader):\n",
    "    # REAL-------\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = next(iter(test_loader)).detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name+'_real_images.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def samples_generated(name, data_loader, extra_name=''):\n",
    "    # GENERATIONS-------\n",
    "    model_best = torch.load(name + '.model', weights_only=False)\n",
    "    model_best.eval()\n",
    "\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = model_best.sample(batch_size=num_x * num_y)\n",
    "    x = x.detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name + '_generated_images' + extra_name + '.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "def samples_diffusion(name, data_loader, extra_name=''):\n",
    "    x = next(iter(data_loader))\n",
    "\n",
    "    # GENERATIONS-------\n",
    "    model_best = torch.load(name + '.model', weights_only=False)\n",
    "    model_best.eval()\n",
    "\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    z = model_best.sample_diffusion(x)\n",
    "    z = z.detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(z[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name + '_generated_diffusion' + extra_name + '.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "def plot_curve(name, nll_val):\n",
    "    plt.plot(np.arange(len(nll_val)), nll_val, linewidth='3')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('nll')\n",
    "    plt.savefig(name + '_nll_val_curve.pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umU3VYKzMbDt"
   },
   "source": [
    "**Training step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NxkUZ1xVLbm_"
   },
   "outputs": [],
   "source": [
    "def training(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader):\n",
    "    nll_val = []\n",
    "    best_nll = 1000.\n",
    "    patience = 0\n",
    "\n",
    "    # Main loop\n",
    "    for e in range(num_epochs):\n",
    "        # TRAINING\n",
    "        model.train()\n",
    "        for indx_batch, batch in enumerate(training_loader):\n",
    "            loss = model.forward(batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        loss_val = evaluation(val_loader, model_best=model, epoch=e)\n",
    "        nll_val.append(loss_val)  # save for plotting\n",
    "\n",
    "        if e == 0:\n",
    "            print('saved!')\n",
    "            torch.save(model, name + '.model')\n",
    "            best_nll = loss_val\n",
    "        else:\n",
    "            if loss_val < best_nll:\n",
    "                print('saved!')\n",
    "                torch.save(model, name + '.model')\n",
    "                best_nll = loss_val\n",
    "                patience = 0\n",
    "\n",
    "                samples_generated(name, val_loader, extra_name=\"_epoch_\" + str(e))\n",
    "            else:\n",
    "                patience = patience + 1\n",
    "\n",
    "        if patience > max_patience:\n",
    "            break\n",
    "\n",
    "    nll_val = np.asarray(nll_val)\n",
    "\n",
    "    return nll_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BXJ9dN0MinB"
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsF7f-Q-MkWu"
   },
   "source": [
    "**Initialize datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = tt.Lambda(lambda x: 2. * (x / 17.) - 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fqZKMNM0LdQ1"
   },
   "outputs": [],
   "source": [
    "train_data = Digits(mode='train', transforms=transforms)\n",
    "val_data = Digits(mode='val', transforms=transforms)\n",
    "test_data = Digits(mode='test', transforms=transforms)\n",
    "\n",
    "training_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lEKUznpMns7"
   },
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ANQo7LrGLjIN"
   },
   "outputs": [],
   "source": [
    "D = 64   # input dimension\n",
    "\n",
    "M = 256  # the number of neurons in scale (s) and translation (t) nets\n",
    "\n",
    "T = 5\n",
    "\n",
    "beta = 0.9\n",
    "\n",
    "lr = 1e-3 # learning rate\n",
    "num_epochs = 1000 # max. number of epochs\n",
    "max_patience = 50 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7APXeunMrDh"
   },
   "source": [
    "**Creating a folder for results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bjSUn1eWLkWm"
   },
   "outputs": [],
   "source": [
    "name = 'ddmg' + '_' + str(T) + '_' + str(beta)\n",
    "if not (os.path.exists('results/')):\n",
    "    os.mkdir('results/')\n",
    "result_dir = 'results/' + name + '/'\n",
    "if not (os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hpwm6LWUMulQ"
   },
   "source": [
    "**Initializing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FrnNsCqQLmK3",
    "outputId": "5f0cf2b1-0a96-4f5c-da9e-f78f909a5259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDGM by JT.\n"
     ]
    }
   ],
   "source": [
    "p_dnns = [nn.Sequential(nn.Linear(D, M), nn.LeakyReLU(),\n",
    "                        nn.Linear(M, M), nn.LeakyReLU(),\n",
    "                        nn.Linear(M, M), nn.LeakyReLU(),\n",
    "                        nn.Linear(M, 2 * D)) for _ in range(T-1)]\n",
    "\n",
    "decoder_net = nn.Sequential(nn.Linear(D, M*2), nn.LeakyReLU(),\n",
    "                            nn.Linear(M*2, M*2), nn.LeakyReLU(),\n",
    "                            nn.Linear(M*2, M*2), nn.LeakyReLU(),\n",
    "                            nn.Linear(M*2, D), nn.Tanh())\n",
    "\n",
    "\n",
    "# Eventually, we initialize the full model\n",
    "model = DDGM(p_dnns, decoder_net, beta=beta, T=T, D=D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SzTemY3NSxO"
   },
   "source": [
    "**Optimizer - here we use Adamax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "R9TZtLVtLoWc"
   },
   "outputs": [],
   "source": [
    "# OPTIMIZER\n",
    "optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNf__W_ONVHA"
   },
   "source": [
    "**Training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhqHgluGLqIC",
    "outputId": "c52fa1e4-3376-4bff-9f87-6f03613c4e42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, val nll=161.739580078125\n",
      "saved!\n",
      "Epoch: 1, val nll=161.19608537946428\n",
      "saved!\n",
      "Epoch: 2, val nll=161.62776785714286\n",
      "Epoch: 3, val nll=160.30395228794643\n",
      "saved!\n",
      "Epoch: 4, val nll=160.87347935267857\n",
      "Epoch: 5, val nll=161.10908482142858\n",
      "Epoch: 6, val nll=160.72370814732142\n",
      "Epoch: 7, val nll=161.3745103236607\n",
      "Epoch: 8, val nll=161.48468470982144\n",
      "Epoch: 9, val nll=160.329560546875\n",
      "Epoch: 10, val nll=159.97327287946428\n",
      "saved!\n",
      "Epoch: 11, val nll=161.14704380580358\n",
      "Epoch: 12, val nll=159.89586774553572\n",
      "saved!\n",
      "Epoch: 13, val nll=160.9863364955357\n",
      "Epoch: 14, val nll=160.7604087611607\n",
      "Epoch: 15, val nll=160.48469308035715\n",
      "Epoch: 16, val nll=160.61872767857142\n",
      "Epoch: 17, val nll=160.65603376116073\n",
      "Epoch: 18, val nll=160.8767103794643\n",
      "Epoch: 19, val nll=160.17714285714285\n",
      "Epoch: 20, val nll=160.47283203125\n",
      "Epoch: 21, val nll=160.31826869419643\n",
      "Epoch: 22, val nll=160.78844308035715\n",
      "Epoch: 23, val nll=160.1862193080357\n",
      "Epoch: 24, val nll=159.9906333705357\n",
      "Epoch: 25, val nll=160.27593331473216\n",
      "Epoch: 26, val nll=160.41001116071428\n",
      "Epoch: 27, val nll=160.11924386160715\n",
      "Epoch: 28, val nll=160.62572963169643\n",
      "Epoch: 29, val nll=160.01840959821428\n",
      "Epoch: 30, val nll=160.47393275669643\n",
      "Epoch: 31, val nll=160.23778878348213\n",
      "Epoch: 32, val nll=160.88375558035713\n",
      "Epoch: 33, val nll=160.48445591517856\n",
      "Epoch: 34, val nll=161.15716378348213\n",
      "Epoch: 35, val nll=160.28560546875\n",
      "Epoch: 36, val nll=160.65120396205356\n",
      "Epoch: 37, val nll=160.41967075892856\n",
      "Epoch: 38, val nll=160.0219419642857\n",
      "Epoch: 39, val nll=161.29901925223214\n",
      "Epoch: 40, val nll=160.20732003348215\n",
      "Epoch: 41, val nll=161.08748325892856\n",
      "Epoch: 42, val nll=160.84904994419642\n",
      "Epoch: 43, val nll=160.82631696428572\n",
      "Epoch: 44, val nll=160.02264369419643\n",
      "Epoch: 45, val nll=160.54935686383928\n",
      "Epoch: 46, val nll=160.29909040178572\n",
      "Epoch: 47, val nll=160.5287890625\n",
      "Epoch: 48, val nll=160.29391741071427\n",
      "Epoch: 49, val nll=160.225419921875\n",
      "Epoch: 50, val nll=160.770439453125\n",
      "Epoch: 51, val nll=160.42862444196427\n",
      "Epoch: 52, val nll=160.6260546875\n",
      "Epoch: 53, val nll=159.81215680803572\n",
      "saved!\n",
      "Epoch: 54, val nll=160.68330078125\n",
      "Epoch: 55, val nll=160.0445982142857\n",
      "Epoch: 56, val nll=160.14644810267856\n",
      "Epoch: 57, val nll=159.6785044642857\n",
      "saved!\n",
      "Epoch: 58, val nll=160.09210239955357\n",
      "Epoch: 59, val nll=160.2376171875\n",
      "Epoch: 60, val nll=160.074560546875\n",
      "Epoch: 61, val nll=160.11888392857142\n",
      "Epoch: 62, val nll=160.12103236607143\n",
      "Epoch: 63, val nll=161.21147042410715\n",
      "Epoch: 64, val nll=160.2945884486607\n",
      "Epoch: 65, val nll=160.53639090401785\n",
      "Epoch: 66, val nll=160.21017159598213\n",
      "Epoch: 67, val nll=160.01305524553572\n",
      "Epoch: 68, val nll=160.03978934151786\n",
      "Epoch: 69, val nll=160.30499441964287\n",
      "Epoch: 70, val nll=159.84226004464287\n",
      "Epoch: 71, val nll=160.53643833705357\n",
      "Epoch: 72, val nll=159.8246568080357\n",
      "Epoch: 73, val nll=160.1821875\n",
      "Epoch: 74, val nll=160.5767103794643\n",
      "Epoch: 75, val nll=161.50421316964287\n",
      "Epoch: 76, val nll=160.305478515625\n",
      "Epoch: 77, val nll=160.52713448660714\n",
      "Epoch: 78, val nll=160.26919921875\n",
      "Epoch: 79, val nll=160.2828696986607\n",
      "Epoch: 80, val nll=160.44955078125\n",
      "Epoch: 81, val nll=159.7822056361607\n",
      "Epoch: 82, val nll=161.02706333705356\n",
      "Epoch: 83, val nll=160.883212890625\n",
      "Epoch: 84, val nll=160.86027622767858\n",
      "Epoch: 85, val nll=160.25101283482144\n",
      "Epoch: 86, val nll=160.66720005580356\n",
      "Epoch: 87, val nll=160.13365652901786\n",
      "Epoch: 88, val nll=159.93473353794644\n",
      "Epoch: 89, val nll=160.32127232142858\n",
      "Epoch: 90, val nll=159.83516462053572\n",
      "Epoch: 91, val nll=159.43283761160714\n",
      "saved!\n",
      "Epoch: 92, val nll=160.0173353794643\n",
      "Epoch: 93, val nll=160.08306919642857\n",
      "Epoch: 94, val nll=160.57597935267856\n",
      "Epoch: 95, val nll=160.48517857142858\n",
      "Epoch: 96, val nll=160.2592466517857\n",
      "Epoch: 97, val nll=159.981875\n",
      "Epoch: 98, val nll=159.51004185267857\n",
      "Epoch: 99, val nll=160.07649135044642\n",
      "Epoch: 100, val nll=160.05283482142858\n",
      "Epoch: 101, val nll=160.7751548549107\n",
      "Epoch: 102, val nll=159.78414760044643\n",
      "Epoch: 103, val nll=160.4912318638393\n",
      "Epoch: 104, val nll=160.47507533482144\n",
      "Epoch: 105, val nll=160.10202287946427\n",
      "Epoch: 106, val nll=159.72519810267858\n",
      "Epoch: 107, val nll=159.823671875\n",
      "Epoch: 108, val nll=160.1656919642857\n",
      "Epoch: 109, val nll=159.82945172991072\n",
      "Epoch: 110, val nll=160.23854213169642\n",
      "Epoch: 111, val nll=160.3855078125\n",
      "Epoch: 112, val nll=159.98082728794643\n",
      "Epoch: 113, val nll=159.77415178571428\n",
      "Epoch: 114, val nll=160.73814174107142\n",
      "Epoch: 115, val nll=160.46108816964286\n",
      "Epoch: 116, val nll=160.07213727678572\n",
      "Epoch: 117, val nll=160.136279296875\n",
      "Epoch: 118, val nll=160.94056919642858\n",
      "Epoch: 119, val nll=160.0546888950893\n",
      "Epoch: 120, val nll=160.7818638392857\n",
      "Epoch: 121, val nll=160.64229910714286\n",
      "Epoch: 122, val nll=160.20688197544644\n",
      "Epoch: 123, val nll=160.15920479910713\n",
      "Epoch: 124, val nll=160.592880859375\n",
      "Epoch: 125, val nll=159.94330357142857\n",
      "Epoch: 126, val nll=160.5678111049107\n",
      "Epoch: 127, val nll=160.5005552455357\n",
      "Epoch: 128, val nll=160.09912109375\n",
      "Epoch: 129, val nll=160.25911969866073\n",
      "Epoch: 130, val nll=160.29371930803572\n",
      "Epoch: 131, val nll=160.481279296875\n",
      "Epoch: 132, val nll=160.92883928571428\n",
      "Epoch: 133, val nll=160.07486328125\n",
      "Epoch: 134, val nll=160.04281110491073\n",
      "Epoch: 135, val nll=160.22703543526785\n",
      "Epoch: 136, val nll=160.07682338169644\n",
      "Epoch: 137, val nll=160.09619140625\n",
      "Epoch: 138, val nll=159.53125697544644\n",
      "Epoch: 139, val nll=160.43824916294642\n",
      "Epoch: 140, val nll=160.77781529017858\n",
      "Epoch: 141, val nll=159.87933314732143\n",
      "Epoch: 142, val nll=160.73979352678572\n"
     ]
    }
   ],
   "source": [
    "# Training procedure\n",
    "nll_val = training(name=result_dir + name, max_patience=max_patience, num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                       training_loader=training_loader, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3XTxgEcNXfp"
   },
   "source": [
    "**The final evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "okK1mV_-LrRU",
    "outputId": "4664693f-742d-4453-94cf-d051d2efa9be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL LOSS: nll=159.6836680299217\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluation(name=result_dir + name, test_loader=test_loader)\n",
    "f = open(result_dir + name + '_test_loss.txt', \"w\")\n",
    "f.write(str(test_loss))\n",
    "f.close()\n",
    "\n",
    "samples_real(result_dir + name, test_loader)\n",
    "\n",
    "plot_curve(result_dir + name, nll_val)\n",
    "\n",
    "samples_generated(result_dir + name, test_loader, extra_name='FINAL')\n",
    "samples_diffusion(result_dir + name, test_loader, extra_name='DIFFUSION')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "vae_priors.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
